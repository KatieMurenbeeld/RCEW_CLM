---
title: "Reynold's Creek Experimental Watershed: Single Point Simulations"
author: "Katie Murenbeeld"
date: "07/31/2020"
output:
  html_document:
    toc: true
    toc_depth: 2
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## 1. Introduction

The purpose of this technical note is to familiarize a LEAF lab user (or any user) with setting up and running a single point climate simulation at the Reynold's Creek Experimental Watershed (RCEW) using the Community Terrestrial Systems Model (CTSM) with standard climate forcing data or meterological data from one of the AmeriFlux towers on the site. 

In this document, I am assuming that you have a small or large allocation on the National Center for Atmospheric Research's (NCAR) supercomputer Cheyenne. At this time CLM is not ported on the high performance computers (HPC), R2 and Borah, at Boise State, but this is a goal to complete soon. For this note, I am also assuming users have an active NCAR project code, a conversational knowledge of a shell type language (bash, sh, csh, tsh, etc.), and a basic understanding of git and github. 

The genreal outline of this technical note will be as followes:

* First, a little background on Reynold's Creek and CESM.
* Section 2: Setting up the file structure on Cheyenne and cloning CTSM
* Section 3: Running Point CLM (PTCLM) make tools to generate the single point surfacedata files needed for running simulations at the tower site of choice.
* Section 4: Running an accelerated spin up for thw tower site.
* Section 5: Running simulations at your tower site!
* Section 6 Examining model output.
* Section 7: A list of useful links at the end to serve a quick reference list. 

### 1.1 Reynold's Creek Experimental Watershed

Reynold's Creek Experimental Watershed (RCEW), located in southwestern Idaho, was established in 1960 to serve as an "outdoor hydrological laboratory". The RCEW is now a part of the Critical Zone Observatory (CZO). Climate and soil data from RCEW is regularly collected, publically avaiable, and is useful for understanding the dynmaincs of the water, energy, and nutrient cycles of the Great Basin as well as the Interior Pacific Northwest. 

More information on RCEW as a part of the CZO can be found [here](https://czo-archive.criticalzone.org/reynolds/infrastructure/field-area/reynolds-creek-experimental-watershed/) and information about available data and data access can be found [here](https://www.ars.usda.gov/pacific-west-area/boise-id/northwest-watershed-research-center/docs/reynolds-creek-experimental-watershed-data/).

```{r clm_fig01, echo=FALSE, eval=TRUE, fig.cap="The Eddy covariance tower at Reynold's Mountain East"}
knitr::include_graphics("figures/ReyMtn4_900_675_80auto.jpg")
```

### 1.2 The Community Earth Systems Model (CESM) and the Community Terrestrial Systems Model (CTSM)

The Community Earth Systems Model [CESM](https://www.cesm.ucar.edu/) was created at NCAR in 1983 and has been in use with continual updates ever since. CESM is a global atmosphere model developed to understand and predict Earth's climate. More history about the development of CESM can be found [here](https://www.cesm.ucar.edu/about/?ref=hp).

The Community Terrestrial Systems Model [CTSM](https://www.cesm.ucar.edu/models/cesm2/land/) or [CLM](https://www.cesm.ucar.edu/models/clm/) is the land model componentof the CESM. Often, one may see or hear CTSM refered to as CLM (Community Land Model). Technically, CLM is a specific component to the CTSM, but the terms are often used interchangably. 

Instructions for this tech note have been edited and aggregated from the escomp [CLM5.0 User's guide](https://escomp.github.io/ctsm-docs/versions/release-clm5.0/html/users_guide/index.html) specifically section 1.7 and the [CLM4.5 User's Guide](https://www.cesm.ucar.edu/models/cesm1.2/clm/models/lnd/clm/doc/UsersGuide/f101.html), specifically Chapter 5.  


## 2. File Structure and Cloning CTSM

### 2.1 File Structure

If you don't have a git working directory set up already on Cheyenne, do so now. It is a best practice to keep projects in their own work directory within this git working directory. 

```{bash set_dir, echo=TRUE, eval=FALSE}
cd /glade/work/$USER/ # go to your work directory on Glade
mkdir git             # create a new folder that will be the parent for future projects using CLM/CTSM
cd git                # go to the newly created git folder
```

### 2.2 Cloning CTSM

From your newly created git folder, clone the CLM/CTSM code. There may be updates to the cloning and set up process in the future. The [ESCOMP/CTSM](https://github.com/ESCOMP/CTSM) github and github [wiki](https://github.com/ESCOMP/CTSM/wiki) page are good references to have bookmarked. See the [Quick Start guide](https://github.com/ESCOMP/CTSM/wiki/CTSM-Quickstart-Guide-for-Users) for more cloning information. 

The following code will point to the latest CTSM release:

```{bash git_clone, echo=TRUE, eval=FALSE}
# Check out the latest release branch and create a new branch for your project

# Here I am cloning the most recent release to a new branch and directory "ctsm-rcew"
git clone -b release-clm5.0 https://github.com/ESCOMP/CTSM.git ctsm_rcew 

# Go to the newly created directory
# A new directory should have been created for your project
cd ctsm_rcew

# Check to see the branches you have now created. There should be a master (or main) as well as a ctsm_rcew branch. The ctsm_rcew branch should have a star next to it meaning that is the active branch or branch you are working in.
git branch   

# If no new branch, create your own.
git checkout -b ctsm_rcew
# Explore the contents of the new directory
ls   
```

Notice that there is a folder within your project direcotry named manage_externals. This contains a very important script, checkout_externals, which downloads all of the components required for building and running CTSM. These include: CLM (land model component), CISM (sea-ice component), RTM (river routing component), MOSART (river routing component), CIME (contains scripts and tools for running CESM), CMEPS (Earth prediction option of CIME), FATES (dynamic vegetation option of CLM), and PTCLM (point simulation option of CLM). More information about checkout_externals can be found in the README_EXTERNALS.rst file in your project folder. 

To checkout the externals:

```{bash checkout_externals, echo=TRUE, eval=FALSE}
./manage_externals/checkout_externals
```

It is also a good idea to create separate folders for different projects in your git directory. You can either re-clone ctsm for each proect or do a recursive copy of another project.

For example, I have several projects that live in my git folder.

```{bash git_folder, echo=TRUE, eval=FALSE}
cd /glade/work/katiem/git
ls
> ctsm  ctsm_py  ctsm_sits ctsm_rcew
```


## 3. Set Up for Point Simulations (PTCLM)

The **P**oin**T** **CLM** runs through the steps for creating single point domain and surface data files (link to html for single point and region surface data file generation). PTCLM is a simpler way to create these files specifically for Ameriflux tower sites. The file PTCLMmkdata runs the tools to get datasets set up, and copies them to a location you can use, including the changes needed for a case to use the dataset with namelist and XML changes. There are a few steps you will need to take before you can run the PTCLMmkdata script. For more information on the PTCLMmkdata script see the README file here: 
$CTSMROOT/tools/PTCLM/

*Note* you will setup the **CTSMROOT** in the next code block. 

### 3.1 Site Specific Data

**First**, you will need to add tower site specific data to your location of interest. For more information see the CLM5.0 User's Guide [Adding PTCLM site data](https://escomp.github.io/ctsm-docs/versions/release-clm5.0/html/users_guide/running-PTCLM/adding-ptclm-site-data.html). Go to CTSMROOT/tools/PTCLM/PTCLM_sitedata. 

```{bash, site_data, echo=TRUE, eval=FALSE}
# First, set up your "root" environment
CTSMROOT=/glade/work/katiem/git/ctsm_rcew
# Then, change to the PTCLM_sitedata folder
cd $CTSMROOT/tools/PTCLM/PTCLM_sitedata
```

There you will find three different text files. One for site data (PTCLMDATA_sitedata.txt), one for plant functional type data (PTCLMDATA_pftdata.txt), and one for soils data (PTCLMDATA_soildata.txt). 

The **PTCLMDATA_sitedata.txt** contains the following (comma separated) headers: site_code,name,state,lon,lat,elev,startyear,endyear,alignyear,timestep,campaign

* **site_code**: abbreviation for the tower site
* **name**: long name for the tower site, make sure to use ""
* **state**: state where tower site is located, use abbrevation
* **lon**: longitude location of the tower site (decimal degrees)
* **lat**: latitude of the tower site (decimal degrees)
* **elev**: elevation of the tower site (meters)
* **startyear**: year when data collection began
* **endyear**: year when data collection ended
* **alingyear**: currently unused, use *startyear* as a filler
* **timestep**: timestep that data is collected (minutes)
* **campaign**: funding for the site, for example AmeriFlux, Fluxnet-Canada, etc.

For RCEW we will be using the Reynolds Mountain East tower site, so the following information can be added to the **PTCLMDATA_sitedata.txt** using your text editor of choice (I use vim). 

US-Rwe,"RCEW Reynolds Mountain East",ID,-116.7591023,43.0653469,2098,2003,2007,2003,30,AmeriFlux

The **PTCLMDATA_soildata.txt** contains the following (comma separated) headers: site_code,soil_depth,n_layers,layer_depth,layer_sand%,layer_clay%

* **site_cade**: abbreviation for the tower site
* **soil_depth**: not currently in use, enter -999 as the value
* **n_layers**: only 1 soil layer is given, enter 1 as the value
* **layer_depth**: not currently in use, enter -999 as the value
* **layer_sand%**: percent sand, used to set the soil texture
* **layer_clay%**: percent clay, used to set the soil texture

Within the Pedotransferfunctions....link to modules and explanation of how certain hydraulic properties are calculated...

The **PTCLMDATA_pftdata.txt** contains the following (comma separated) headers:
site_code,pft_f1,pft_c1,pft_f2,pft_c2,pft_f3,pft_c3,pft_f4,pft_c4,pft_f5,pft_c5

* **site_cade**: abbreviation for the tower site
* **pft_c1-5**: the index number of a plant functional type, currently PTCLM only supports up to 5 pfts at a site.
* **pft_f1-5**: the fraction (as a percent) of the site covered by the pft

The list of pft indexes can be found here <link>:

Make a table of pfts with the acronym and index #

### 3.2 Loading Modules
Modules are ... You will need to load the appropriate modules in a specific order. order. **NOTE** Depending on if you use miniconda you may or may mot need to load all of the modules if they are already in the miniconda environment. For example, here I do not *module load python/2* because I will activate a python 2 miniconda environment later.

Modules: 

* **ncarenv**: set up default NCAR environments (needed for capability to enter a qinteractive session)
* **intel**: both load intel compilers: C (icc), C++ (icpc), and Fortran (ifort)
* **ncarcompilers**: loads NCAR compiler wrappers, wraps usual serial and parallel compilers to include all the required libraries and header files. *Needs a compiler loaded first (intel/17.0.1 or 18.0.5)
* **nco**: NCO toolkit manipulates and analyzes data stored in netCDF-accessible formats (DAP, HDF4, and HDF5). Uses ncarenv/1.3, gnu/8.3.0, ncarcompilers/0.5.0
* **netcdf**: software libraries and dataformats for NetCDF. *Needs a compiler loaded first (intel/17.0.1 or 18.0.5)
* **ncl**: loads NCAR Command Language (ncl) package.*Needs a compiler loaded first (intel/17.0.1 or 18.0.5)
* **mpt**: The HPE Message Passing Interface (MPI). *Needs a compiler loaded first (intel/17.0.1 18.0.5)
* **esmf_libs**: Makes Earth Systems Model Framework (ESMF) libraries available. Needs a compiler loaded first (intel/17.0.1 or 18.0.5)
* **ncview**: Loads ncview, which is a quick way to visualize outputs. Type ncview file_name.nc to open a graphical user interface (GUI) for data visualization. 
* **python**: optional, version 2 seems to work the best in this case

```{bash ptcml_modload, echo=TRUE, eval=FALSE}
module load ncarenv/1.3 
module load intel/17.0.1 
module load ncarcompilers/0.5.0 
module load nco/4.7.9 
module load netcdf/4.7.3 
module load ncl/6.6.2 
module load mpt/2.22 
module load esmf_libs/7.1.0r 
module load ncview/2.1.7 
# module load python/2.*, optional
```

### 3.3 Running PTCLMmkdata 

Change directory to the PTCLM folder. From there execute the buildtools script. Buildtools will...

```{bash ptcml_folder, echo=TRUE, eval=FALSE}
CTSMROOT=/glade/work/katiem/git/ctsm_rcew
cd $CTSMROOT/tools/PTCLM
./buildtools

## Should see this text.
## Successfully built CLM tools needed to create datasets for PTCLM
```

There is a known issue within the PTCLMmkdata code which will need to be addressed before you can continue on with the process. Use the text editor of your choice to open PTCLMmkdata. In line 552 you will need to remove the "export" command.

```{bash PTCLMmkdata, echo=TRUE, eval=FALSE}
- cmd = "export REGRID_PROC=1; "+mkmapdat_dir+"/mkmapdata.sh --gridfile "+scripgridfile+" --res "+clmres+" --gridtype regional -v > "+mapdir+"/mkmapdata.log";
+ cmd = mkmapdat_dir+"/mkmapdata.sh --gridfile "+scripgridfile+" --res "+clmres+" --gridtype regional -v > "+mapdir+"/mkmapdata.log";
```

Once all of the modules are loaded, the tools are built, and the PTCLMmkdata script is updated, open up a qinteractive session in order to complete the map generation and file creation process. The process can take several hours, so I suggest setting the walltime to 6 hours.

```{bash ptcml_qint, echo=TRUE, eval=FALSE}
qinteractive -X -A UBOI0006 -l walltime=06:00:00
```

Load a python 2 compatible miniconda environment (optional).

```{bash ptclm_py2, echo=TRUE, eval=FALSE}
conda activate python2
```

After entering the qinteractive environment, you will need to reset environmental variables.
```{bash ptml_setenv, echo=TRUE, eval=FALSE}
CSMDATA=/glade/p/cesm/cseg/inputdata
CTSMROOT=/glade/work/katiem/git/ctsm_rcew
SITE=US-Rwe
```

Next, run the PTCLMsublist, which will... 
```{bash ptclm_sublist, echo=TRUE, eval=FALSE}
./PTCLMsublist -l $SITE -d $CSMDATA -o --verbose --account=UBOI0003 --mach=cheyenne
```

PTCLMsublist will output a command to copy and paste into the terminal. It will look something like this...
```{bash ptclm_mkdata, echo=TRUE, eval=FALSE}
./PTCLMmkdata -s US-Rwe -d /glade/p/cesm/cseg/inputdata
```

What is this command doing? 
For more information on the PTCLMmkdata script see the README file here: 
$CTSMROOT/tools/PTCLM/

Basically, PTCLMmkdata is a python script that runs through the process of creating the 



Again, this process can take a long time. You may need to run this command multiple times. However, once the mapping files are created they will be skipped over if you have to rerun the PTCLMmkdata command. 

### 3.4 Where does my data go?

Running
```{bash data_loc, echo=TRUE, eval=FALSE}
./PTCLMmkdata --help
>...
--mydatadir=MYDATADIR
                        Directory of where to put your data files (files will
                        be under subdirectories for each site) (default: /glad
                        e/work/katiem/git/ctsm_rcew/tools/PTCLM/mydatafiles)
...
```
will show the default data directory. In this case mydatadir = /glade/work/katiem/git/ctsm_rcew/tools/PTCLM/mydatafiles
                        
You can set a different file path as an environmental variable, but I find that the default works fine. 
```{bash ptclm_datadir, echo=TRUE, eval=FALSE}
MYDATADIR=/glade/work/katiem/srfdata/
./PTCLMmkdata -s US-Rwe --mydatadir=$MYDATADIR -d /glade/p/cesm/cseg/inputdata
```


Different folders for each site you run PTCMLmkdata will be found in your data directory (mydatadir). 

The folders will have the following naming convention: 1x1_*site-name*. 

## 4. Accelerated Spin Up

Something something, working with soils, getting to a steady state. Need to do a spin up. 

Within this section, also some of the (not so basic) basics for creating and submitting a CLM "case", or simulation.

Make sure you are in your CTSMROOT (the base directory where "cime" and "components" live). Then change directories to cime/scripts. Within the cime/scripts directory is the create_newcase script.  

```{bash spinup_createnew, echo=TRUE, eval=FALSE}
cd cime/scripts/

./create_newcase --compset 2000_DATM%GSWP3v1_CLM50%BGC_SICE_SOCN_SROF_SGLC_SWAV --res f09_g17 --case /glade/work/katiem/SITS_cases/Rwe1_CLM50spinup_001 --run-unsupported --project UBOI0003
```

In order to create a new case there are 3 required arguments: compset, res, and case. The compset... The res... The case... The other arguments used here are run-unsupported and project. The run-unsupported ... The project... If you are interested in the arguments please see the help documentation by running

```{bash newcase_help, echo=TRUE, eval=FALSE}
./create_newcase --help
```

Once the new case is created, move into the newly created case directory.

```{bash spinup_cdcase, echo=TRUE, eval=FALSE}
cd /glade/work/katiem/SITS_cases/Rwe1_CLM50spinup_001
```

From here you will update some environmental variables for the case using the command xmlchange. These variables are specific to the machine (computer). As a note. ./xmlquery can be used to look up specfic environmental variables in case you can't remember the name. 

```{bash xmlquery, echo=TRUE, eval=FALSE}
./xmlquery WALL
>
```


For a list and more information on the variables you can search for the variables on this webpage http://www.cesm.ucar.edu/models/cesm2/settings/2.1.0/drv_input.html. (I suggest bookmarking this page!)

```{bash env_mach_pes, echo=TRUE, eval=FALSE}
./xmlchange MPILIB=mpi-serial
./xmlchange --file env_mach_pes.xml --id COST_PES --val 36
./xmlchange --file env_mach_pes.xml --id TOTALPES --val 1
./xmlchange --file env_mach_pes.xml --id NTASKS --val 1
./xmlchange --file env_mach_pes.xml --id NTASKS_PER_INST --val 1
./xmlchange --file env_mach_pes.xml --id ROOTPE --val 0
```

After you've updated the above variables, you are now ready to setup the case. When you setup the case 

```{bash spinup_casesetup, echo=TRUE, eval=FALSE}
# Remember you are still in the case directory

./case.setup

```

Once your case is setup you will update many more variables using the ./xmlchange command. 

```{bash env_run01, echo=TRUE, eval=FALSE}
./xmlchange --file env_run.xml --id CLM_FORCE_COLDSTART --val on
./xmlchange --file env_run.xml --id CLM_NML_USE_CASE --val 1850_control
./xmlchange --file env_run.xml --id DATM_CLMNCEP_YR_START --val 1901
./xmlchange --file env_run.xml --id DATM_CLMNCEP_YR_END --val 1920
./xmlchange --file env_run.xml --id DATM_PRESAERO --val clim_1850
./xmlchange --file env_run.xml --id CCSM_CO2_PPMV --val 284.7
./xmlchange --file env_run.xml --id STOP_OPTION --val nyears
./xmlchange --file env_run.xml --id RUN_REFDATE --val 0001-01-01
./xmlchange --file env_run.xml --id RUN_STARTDATE --val 0001-01-01

# Turn on the accelerated spinup
./xmlchange --file env_run.xml --id CLM_ACCELERATED_SPINUP --val on

# Set the total number of years to run. 
./xmlchange --file env_run.xml --id STOP_N --val 500
# Set the interval (in years) where a restart file will be created.
./xmlchange --file env_run.xml --id REST_N --val 100

```

Next, you will point to the domain files you created in [Section 3]. 

```{bash spinup_domain, echo=TRUE, eval=FALSE}

./xmlchange --file env_run.xml --id ATM_DOMAIN_FILE --val domain.lnd.1x1pt_US-Rwe_navy.200721.nc
./xmlchange --file env_run.xml --id ATM_DOMAIN_PATH --val /glade/work/katiem/SITS_data
./xmlchange --file env_run.xml --id LND_DOMAIN_FILE --val domain.lnd.1x1pt_US-Rwe_navy.200721.nc
./xmlchange --file env_run.xml --id LND_DOMAIN_PATH --val /glade/work/katiem/SITS_data


```

Next, you will update the user_nl_clm (the CLM user namelist) file. In this file... You will set the surface data file to the surfdata file you created in section 3. 

```{bash spinup_clmusernl, echo=TRUE, eval=FALSE}
echo "fsurdat = '/glade/work/katiem/SITS_data/surfdata_1x1pt_US-Rwe_hist_16pfts_Irrig_CMIP6_simyr2000_c200721.nc'" >> user_nl_clm
echo "hist_mfilt = 20" >> user_nl_clm
echo "hist_nhtfrq = -8760" >> user_nl_clm

echo "hist_empty_htapes = .true." >> user_nl_clm
echo "hist_fincl1 = 'TOTECOSYSC', 'TOTECOSYSN', 'TOTSOMC', 'TOTSOMN', 'TOTVEGC', 'TOTVEGN', 'TLAI', 'GPP', 'CPOOL', 'NPP', 'TWS',
'H2OSNO'" >> user_nl_clm

echo "mapalgo = 'nn','nn','nn','nn','nn'" >> user_nl_datm
```

If you have your own climate or atmospheric forcing data to use (for example you want to use the atmospheric data from the flux tower at your site) you can now copy over the user_datm.streams files you created (see section X).

```{bash spinup_ownatmo, echo=TRUE, eval=FALSE}
cp ../Rwe1_CLM50spinup_001/user_datm.streams.txt.* .
```

Double check the your namelist file (user_nl_clm) using your text editor of choice or the command.

```{bash sp_checknl, echo=TRUE, eval=FALSE}
vim user_nl_clm

## or...
cat user_nl_clm
```

Now, build and submit the spinup case!

```{bash sp_build-submit, echo=TRUE, eval=FALSE}
qcmd --./case.build

## This may take a few minutes. When complete you should see:
## MODEL BUILD HAS FINISHED SUCCESSFULLY

./case.submit
```

To check on the progress you can see the jobs you've submitting using the qstat command.

```{bash sp_qstat, echo=TRUE, eval=FALSE}
qstat -u katiem  # the -u argument is for user, so really it is qstat -u $USER
```

You can also check your scratch or scratch archive to check on the progress of the spinup case.

```{bash sp_scratch, echo=TRUE, eval=FALSE}
cd /glade/scratch/$USER/archive/$CASE/
ls 

# or...
cd /glade/scratch/$USER/$CASE/run
ls

```


## 5. Setting Up and Running a Case

## 6. Model Outputs

## 7. Useful References

